# IOMMU与linux-kernel内存管理

## 一、虚拟内存

### 1.1 什么是虚拟内存

**https://www.geeksforgeeks.org/virtual-memory-in-operating-system/**

​		虚拟内存是操作系统使用的一种内存管理技术，即使物理内存 （RAM） 有限，它也能为应用程序提供大型连续内存块的外观。**它允许系统补偿物理内存不足，使更大的应用程序能够在具有较少 RAM 的系统上运行**。

​		**内存层次结构由计算机系统的内存和磁盘组成**，使进程能够在内存中仅使用其地址空间的某些部分进行操作。虚拟内存顾名思义——它是比真实内存更大的内存的错觉。我们将虚拟内存的软件组件称为虚拟内存管理器。虚拟内存的基础是非连续内存分配模型。虚拟内存管理器从内存中删除某些组件，以便为其他组件腾出空间。

​		**虚拟存储的大小受计算机系统的寻址方案和可用辅助内存量的限制，而不是受主存储位置的实际数量限制。**



### 1.2 为什么需要虚拟内存

```less
1. 内存保护
	虚拟内存允许操作系统保护不同进程的内存空间，防止一个进程访问另一个进程的内存。这种隔离可以防止恶意或错误的代码破坏其他程序的数据，增加系统的安全性和稳定性。

2. 内存管理
	虚拟内存提供了一种机制，使得操作系统可以更高效地管理内存。通过使用页表，操作系统可以将虚拟地址映射到物理地址，实现内存分页。这种机制允许操作系统将进程所需的内存部分加载到物理内存中，其余部分存储在磁盘上，从而实现内存的虚拟扩展。

3. 地址空间扩展
	物理内存的大小是有限的，而虚拟内存提供了一种方法，使进程可以认为自己有一个连续的、较大的地址空间。这样，程序不需要担心实际物理内存的限制，可以方便地编写和运行需要大内存的应用。

4. 内存共享和重定位
	虚拟内存允许不同进程共享相同的物理内存，比如共享库。同时，虚拟内存使得程序可以在不同的物理内存地址上运行，而不需要修改代码中的地址引用。操作系统可以在内存中任意位置加载程序，而不需要考虑其在物理内存中的绝对位置。

5. 分页和分段
	通过分页（paging）和分段（segmentation）技术，虚拟内存可以帮助优化内存的使用，减少内存碎片，提高内存的利用效率。这些技术允许将物理内存分成固定大小的块（页）或可变大小的块（段），并将它们动态分配给进程。

6. 简化编程模型
	对于程序员来说，使用虚拟内存简化了编程模型。程序员可以认为他们的程序拥有一个连续的内存空间，而不需要担心物理内存的实际分布和管理。操作系统和硬件负责将虚拟地址转换为物理地址，处理内存的实际分配和管理。

```

**物理地址使用的局限性**，直接使用物理地址会带来很多问题：
		安全性差：所有程序都可以访问物理内存，容易引发安全问题。
		内存碎片：内存管理变得复杂，容易产生内存碎片。
		共享困难：无法方便地实现内存共享。
		地址冲突：多个程序可能会尝试使用相同的物理地址，导致冲突。
	
通过引入虚拟地址和物理地址的映射，现代计算机系统可以更好地管理内存资源，提高系统的性能、安全性和灵活性。



### 1.3 虚拟内存的类型

虚拟内存主要有两种类型：

- **Paging** 
- **Segmentation** 

#### 1.3.1 Paging

```apl
##	分页将内存划分为称为页面的固定大小的小块。当计算机的 RAM 耗尽时，当前未使用的页面将移动到硬盘驱动器中，进入称为交换文件的区域。交换文件充当RAM的扩展名。当再次需要页面时，它会被交换回 RAM，这个过程称为页面交换。这可确保操作系统 （OS） 和应用程序具有足够的内存来运行。

## 	需求分页：按需将页面加载到内存中的过程（每当发生页面错误时）称为需求分页。该过程包括以下步骤，如下所示：
```

![Demand Paging](../typora-image/ezgifcom-gif-maker-(22).webp)

- 如果 CPU 尝试引用主内存中当前不可用的页面，则会生成中断，指示内存访问错误。

- 操作系统将中断的进程置于阻塞状态。要继续执行，操作系统必须将所需的页面带入内存。

- 操作系统根据页表中的映射关系，找到逻辑地址(虚拟地址)对应的页在磁盘或者交换空间中的位置。

- 所需的页面将从逻辑地址空间带到物理地址空间。页面替换算法用于在物理地址空间中替换页面的决策。

    - <span style="color: rgb(200, 100, 100);">一旦操作系统确定了所需页面的位置，接下来会将这个页面从磁盘或者交换空间加载到物理内存中的一个空闲页框（Page Frame）中。</span>
    - <span style="color: rgb(200, 100, 100);">在这个过程中，操作系统将逻辑地址空间中的内容复制到物理地址空间中对应的位置。</span>
    -  <span style="color: rgb(200, 100, 100);">这个过程是逻辑地址到物理地址的映射和转换过程（所以上图中在经过步骤4转换后，确认为p2需要使用），确保了进程后续访问该虚拟地址时能够直接通过物理地址访问数据。</span>

- 操作系统在完成页面调入后，会更新页表，将虚拟地址到物理地址的映射关系添加到页表中。

- 操作系统通知CPU可以继续执行进程，此时，CPU可以直接使用之前发生页错误的虚拟地址，通过已更新的页表，将其转换为物理地址，然后访问相应的数据或指令。

```less
What is Page Fault Service Time? 什么是页面故障服务时间？
	处理页面故障所花费的时间称为页面故障服务时间。页面故障服务时间包括执行上述所有六个步骤所花费的时间。
```



#### 1.3.2 Segmentation

```apl
## Segmentation 将进程的地址空间划分为多个逻辑段（Segment），每个段代表一个逻辑单元（如代码段、数据段等），每个段可以拥有不同的大小和属性。

## 分段将虚拟内存划分为不同大小的段。当前不需要的段可以移动到硬盘驱动器。系统使用区段表来跟踪每个区段的状态，包括它是否在内存中、是否已被修改以及其物理地址。只有在需要时，才会将段映射到进程的地址空间中。
```

**有时，分页和分段一起使用。在这种情况下，内存被划分为多个页面，而段则由多个页面组成。虚拟地址包括段号和页码。**



#### 1.3.3 区别总结

- **管理单位**：Segmentation 按照逻辑单元（段）管理，而 Paging 按照固定大小的块（页）管理。
- **碎片问题**：Segmentation 容易产生外部碎片，Paging 主要解决外部碎片问题，但可能产生内部碎片。
- **复杂度**：Segmentation 管理和维护段表较为复杂，Paging 简化了地址转换和管理，但需要额外的页表。
- **应用**：Segmentation 更适合于动态分段的应用场景，如程序段的动态增长；Paging 更适合于管理固定大小的内存块，适用于虚拟内存系统。



### 1.4 虚拟内存是如何做到补偿物理内存不足

虚拟内存允许系统补偿物理内存不足，使更大的应用程序能够在具有较少 RAM 的系统上运行，主要是通过以下几种机制实现的：

**1. 内存分页 (Paging)**

虚拟内存将进程的地址空间分成固定大小的页（通常为4KB或更大），这些页可以独立地映射到物理内存中的任何位置。如果物理内存不足，一些不活跃的页可以被换出到磁盘上的交换空间（swap space），当需要时再换入物理内存中。这种机制称为分页 (paging)。

- 分页的工作原理

    ：

    1. 当进程访问虚拟地址时，CPU通过页表将虚拟地址转换为物理地址。
    2. 如果所访问的页在物理内存中，直接访问。
    3. 如果所访问的页不在物理内存中，产生缺页中断（page fault），操作系统会将该页从磁盘的交换空间换入物理内存。

**2. 交换空间 (Swap Space)**

交换空间是硬盘上的一个区域，用来临时存放不活跃的内存页。当物理内存不足时，操作系统会将不常用的内存页移到交换空间。这样，系统可以运行需要大内存的应用程序，而不受物理内存的限制。

- 交换空间的工作原理

    ：

    1. 当物理内存不足时，操作系统选择一些不活跃的内存页，并将它们写入交换空间。
    2. 当这些页再次被访问时，操作系统将它们从交换空间读取回物理内存。

**3. 按需分页 (Demand Paging)**

在这种机制下，只有当程序真正访问内存页时，操作系统才会将其加载到物理内存中。未访问的内存页不会占用物理内存。这种机制提高了内存利用率，减少了物理内存的浪费。

- 按需分页的工作原理

    ：

    1. 程序启动时，只加载必要的部分（如程序代码和初始化数据）。
    2. 其他部分（如堆栈和动态分配的内存）在访问时才加载。

**4. 页面置换算法 (Page Replacement Algorithms)**

当物理内存已满且需要加载新的页时，操作系统必须决定哪些页被换出。常见的页面置换算法包括最少最近使用（LRU）、先进先出（FIFO）和最近最少使用（LRU）。这些算法帮助操作系统选择最佳的页换出策略，减少缺页中断的频率，提高系统性能。

- **LRU（Least Recently Used）算法**：选择最久未使用的页进行换出。
- **FIFO（First In, First Out）算法**：选择最早进入内存的页进行换出。
- **LFU（Least Frequently Used）算法**：选择使用频率最低的页进行换出。

**5. 内存映射文件 (Memory-Mapped Files)**

虚拟内存允许进程将文件映射到内存地址空间，这样可以直接对文件进行读写操作，而不需要显式的I/O操作。这种机制也可以用来实现共享内存，以便多个进程共享数据。

- 内存映射文件的工作原理：

    1. 使用 `mmap` 系统调用将文件映射到虚拟内存地址空间。
    2. 进程可以像访问普通内存一样读写文件数据，操作系统负责将这些操作映射到实际的文件I/O。

通过这些机制，虚拟内存可以有效地管理物理内存，提供更大的地址空间，使得应用程序可以在物理内存有限的系统上运行而不会因为内存不足而崩溃。

```apl
总结：通过合理调度（内存---硬盘）之间的存储关系，来实现逻辑上更大的内存需求。
```





## 二、IOMMU

### 1.1使用IOMMU的优势

**内存隔离与保护**：

- **防止设备非法访问内存**：IOMMU可以创建设备与内存之间的映射，从而限制设备访问特定的内存区域。这种隔离保护了内存免受潜在的硬件设备故障或恶意设备攻击。
- **增强安全性**：通过限制设备的内存访问权限，IOMMU可以防止DMA攻击，确保系统的内存安全。

**地址转换**：

- **虚拟地址到物理地址的映射**：IOMMU可以将设备的虚拟地址映射到物理内存地址，使得设备可以像CPU一样使用虚拟内存。这简化了设备驱动程序的设计和开发。
- **支持虚拟化**：在虚拟化环境中，IOMMU允许虚拟机直接访问硬件设备，同时保证不同虚拟机之间的内存隔离，提升虚拟化的性能和安全性。

**改进的性能**：

- **缓存优化**：IOMMU可以利用缓存机制来提高地址转换的效率，减少设备访问内存的延迟。
- **支持大页面（Huge Pages）**：通过支持大页面，IOMMU可以减少页表的开销，提高内存访问的性能。

反之：不使用IOMMU的情况

```less
缺乏内存保护：
	设备可能访问任意内存：没有IOMMU，设备可以直接访问物理内存，这可能导致内存数据被破坏或被恶意读取。
	安全风险：由于没有内存访问控制，系统容易受到DMA攻击，特别是在外部设备连接到系统时。

复杂的地址管理：
	设备需要物理地址：没有IOMMU，设备必须使用物理地址进行内存访问，这增加了驱动程序开发的复杂性。
	内存碎片化：设备直接使用物理内存，可能导致内存碎片化问题，降低内存利用率和系统性能。

虚拟化限制：
	虚拟机访问受限：在虚拟化环境中，没有IOMMU的支持，虚拟机不能直接访问硬件设备，必须通过虚拟化层的中介，这会降低性能和增加延迟。
	资源隔离困难：没有IOMMU，虚拟机之间难以实现有效的内存隔离，增加了虚拟机之间相互干扰的风险。
```

总结：

```apl
安全
硬件加速，性能更高
```



### 1.2 IOMMU的硬件加速如何实现

IOMMU（Input-Output Memory Management Unit，输入输出内存管理单元）的硬件加速设计通常涉及以下几个关键方面：

1. **DMA Remapping Engine（DMA重映射引擎）**：
    - **功能**：DMA Remapping Engine 是 IOMMU 的核心组成部分之一，负责管理设备的 DMA 请求。它能够将设备提供的物理地址映射到正确的虚拟地址，从而确保设备只能访问到授权的内存区域。
    - **实现**：硬件加速的设计中，DMA Remapping Engine 可以高效地执行地址映射，减少了软件处理的开销，提升了数据传输的效率。
2. **TLB（Translation Lookaside Buffer，转译后备缓冲区）优化**：
    - **功能**：TLB 是用于存储最近使用的地址映射信息的高速缓存，可以加速重复的地址转换操作。
    - **实现**：硬件加速设计中，IOMMU 可以优化 TLB 的设计和访问速度，使得常见的地址映射可以快速完成，减少了每次 DMA 操作所需的时间和处理器负载。
3. **集成与优化**：
    - **功能**：现代 IOMMU 设计通常与处理器、系统总线和内存控制器紧密集成，以优化数据传输的效率和安全性。
    - **实现**：通过与处理器和系统总线的紧密协作，IOMMU 可以在硬件层面上管理地址映射和访问控制，避免了软件处理的延迟和性能损失。例如，直接在总线上执行地址转换和权限检查，以减少额外的数据复制和中介操作。
4. **安全性和虚拟化支持**：
    - **功能**：IOMMU 的硬件加速设计强化了安全性，确保每个设备只能访问到其授权的内存区域，从而防止设备的 DMA 操作导致的数据泄露或系统崩溃。
    - **实现**：硬件级别的访问控制和虚拟化支持使得 IOMMU 在多租户环境和高性能计算中得到广泛应用，确保了系统的稳定性和安全性。



### 1.3 虚拟化环境对IOMMU的需求

```less
虚拟化环境通常需要使用 IOMMU（Input-Output Memory Management Unit，输入输出内存管理单元）主要出于安全性和性能隔离的考虑。以下是几个主要的理由：

	安全性和隔离：在虚拟化环境中，多个虚拟机（VM）共享同一台物理主机的硬件资源，包括内存和设备。IOMMU 可以帮助确保每个虚拟机只能访问到其分配的特定内存区域，防止虚拟机之间或者虚拟机与宿主机之间的内存越界访问。这种隔离对于安全性至关重要，可以防止恶意或者错误的访问影响到整个系统的稳定性和安全性。
	DMA访问控制：许多设备使用直接内存访问（DMA）来读取和写入内存。在没有 IOMMU 的情况下，设备可以访问到整个系统的内存空间，这可能会导致数据泄露或者破坏其他虚拟机的数据。通过使用 IOMMU，可以将设备的 DMA 访问限制在特定的虚拟机内存区域，增强对数据的保护和隔离。
	性能优化：IOMMU 不仅提供了安全隔离，还可以在一定程度上优化性能。通过准确映射设备需要访问的内存区域，可以避免不必要的复制和中介操作，提高数据传输的效率和速度。
```



## 三、linux-kernel的MMU

### 2.1 malloc接口

​	<span style="color: rgb(50, 200, 500);">	进程中的所有内存引用都是逻辑地址，在运行时动态转换为物理地址。这意味着进程可以在主内存中交换，使其在执行过程中的不同时间在主内存中占据不同的位置。</span>

​	<span style="color: rgb(50, 200, 500);">	一个进程可以被分解成许多片段，这些片段在执行过程中不需要连续位于主存储器中。动态运行时地址转换和页或段表的使用相结合，可以实现这一点。</span>

```less
Linux 提供的 malloc 接口申请出来的地址是虚拟地址。虚拟地址是操作系统为每个进程提供的地址空间，这些地址在进程之间是隔离的。

虚拟地址的作用
	内存隔离：每个进程都有自己独立的虚拟地址空间，这样一个进程的内存操作不会影响到其他进程。
	内存管理灵活性：虚拟内存允许操作系统将物理内存和存储设备（如硬盘）结合使用。操作系统可以将不常用的数据移到硬盘，从而释放物理内存给更需要的应用程序。
	简化编程：开发者可以使用连续的虚拟地址空间来分配和管理内存，而不需要考虑物理内存的实际分布情况。

malloc 如何工作
	当调用 malloc 申请内存时，操作系统会在进程的虚拟地址空间中分配一块连续的地址区间，并通过页表将这些虚拟地址映射到实际的物理内存。具体步骤如下：
		虚拟内存分配：malloc 分配虚拟地址空间中的一部分。
		页表映射：操作系统将这部分虚拟地址映射到物理内存中的物理地址。
		内存初始化：malloc 函数可能会初始化这段内存区域，使其可以立即使用。

虚拟地址和物理地址的关系
	页表：操作系统通过页表（page table）来管理虚拟地址和物理地址之间的映射关系。每个进程都有自己独立的页表。
	地址转换：当程序访问一个虚拟地址时，CPU 会通过页表将其转换为物理地址，然后进行实际的内存操作。
```

### 2.2 一个程序的执行

**加载程序**：
	当你在终端输入可执行程序的名称并按下回车时，Linux 内核会负责加载这个程序。
	内核首先会解析 ELF 文件头部信息，确定程序入口点（Entry Point），即程序开始执行的地方

**内存映射：**
	内核会为程序分配虚拟内存空间，并将程序的代码段、数据段等内容映射到进程的地址空间中。
	代码段通常是只读的，并且被映射到可执行的虚拟内存区域。
	数据段则包含全局变量和静态变量的初始化数据，被映射到可读写的虚拟内存区域。

**动态链接：**
	如果程序依赖于动态链接的共享库（如 C 库 libc），内核会加载这些共享库，并将它们映射到进程的地址空间中。
	动态链接器（如 ld-linux.so）负责在运行时解析和链接这些共享库，以便程序可以调用它们提供的函数和服务。

**执行程序：**
	一旦所有必要的段和共享库被加载和映射到进程的地址空间中，内核会将控制权转移给程序的入口点，开始执行程序的指令。
	程序在运行时可以访问映射到其地址空间的所有数据和代码，执行其设计的功能。

```apl
## 对于一个执行程序而言：在 Linux 的虚拟内存管理中，程序的数据段、代码段、栈和堆被存储在不同的虚拟内存区域中，这些区域通过页表管理和操作系统的内存管理功能来分配和管理。所以，这部分虚拟内存，具体是存储为segment还是paging，主要看Linux的内存具体管理形式。
```





## 四、IOMMU与linux-kernel的异同

使用 Linux 内核自己的地址转换和 IOMMU 各有其用途和优势，主要区别和原因如下：

**Linux 内核地址转换**

1. **应用级虚拟内存管理**：Linux 内核**通过页表来管理每个进程的虚拟地址空间，并将其映射到物理内存**。这对于普通应用程序来说足够了，可以有效地实现内存隔离和内存保护。
2. **软件实现**：**内核通过软件方式来管理页表**，并处理虚拟地址到物理地址的转换。
3. **CPU 访问**：当 CPU 访问内存时，它通过内核的页表来进行地址转换。这主要涉及到 CPU 的内存访问路径。

**IOMMU（Input-Output Memory Management Unit）**

1. **设备级虚拟内存管理**：IOMMU **专门用于管理 DMA（Direct Memory Access）设备的内存访问**。它为设备提供虚拟地址空间，使设备能够进行虚拟地址访问，而不是直接访问物理地址。
2. **硬件支持**：**IOMMU 提供硬件级的地址转换**，可以在硬件层面上实现高效的地址映射和保护。
3. **设备安全**：使用 IOMMU 可以防止恶意或错误的 DMA 操作，因为 IOMMU 可以隔离和保护内存区域，防止设备访问未授权的内存区域。
4. **多设备协调**：在多设备环境中，IOMMU 可以有效地管理和协调各设备的内存访问，防止设备之间的冲突和内存污染。

**为什么不使用 Linux 内核自己的地址转换**

1. **性能需求**：IOMMU 提供了硬件加速的地址转换，这对于高性能设备（如网络接口卡、GPU 等）的 DMA 操作至关重要。通过硬件支持的地址转换，可以减少延迟，提高数据传输速度。
2. **设备独立性**：一些设备需要独立的内存管理机制，以实现更细粒度的内存控制和安全隔离。IOMMU 提供的功能比内核自己的地址转换更适合这种需求。
3. **安全性和隔离**：IOMMU 可以提供更强的安全性，防止设备之间的非法内存访问，这对于虚拟化环境和多租户系统尤为重要。

**总结**
Linux 内核的地址转换和 IOMMU 都有各自的使用场景和优势。内核地址转换适用于 CPU 的内存访问管理，而 IOMMU 则专门用于 DMA 设备的内存管理和保护。两者结合使用，可以实现更高效和安全的内存管理。
