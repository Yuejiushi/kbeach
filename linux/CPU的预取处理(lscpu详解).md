# CPU的预取处理

## 一、lscpu信息

```shell
[root@localhost ~]# lscpu
Architecture:          x86_64                  # CPU 架构类型，表示 64 位 x86 架构
CPU op-mode(s):        32-bit, 64-bit            # 支持的操作模式，32 位和 64 位模式
Byte Order:            Little Endian             # 字节序，表示数据以小端字节序存储（低字节在前，高字节在后）
CPU(s):                24                        # 总的 CPU 线程数
On-line CPU(s) list:   0-23                      # 当前在线的 CPU 线程列表（0 到 23）
Thread(s) per core:    1                         # 每个核心支持的线程数（没有超线程技术）
Core(s) per socket:    12                        # 每个 CPU 插槽上的核心数
Socket(s):             2                         # CPU 插槽数（系统中有 2 个 CPU 插槽）
NUMA node(s):          2                         # NUMA 节点数（系统有 2 个 NUMA 节点）
Vendor ID:             GenuineIntel               # CPU 厂商标识，表示 Intel 生产的 CPU
CPU family:            6                         # CPU 家族编号，Intel 的 CPU 家族编号
Model:                 63                        # CPU 型号编号，表示具体的 CPU 模型
Model name:            Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz  # CPU 的具体型号和主频
Stepping:              2                         # CPU 步进编号，表示 CPU 的修订版本
CPU MHz:               1199.951                  # 当前 CPU 主频（在节能模式下的频率）
CPU max MHz:           3300.0000                 # 最大 CPU 主频（在性能模式下的频率）
CPU min MHz:           1200.0000                 # 最小 CPU 主频（在节能模式下的频率）
BogoMIPS:              5000.46                   # BogoMIPS 值，用于估算 CPU 的性能（不用于实际性能衡量）
Virtualization:        VT-x                       # 支持的虚拟化技术，表示支持 Intel 的 VT-x 技术
L1d cache:             32K                       # L1 数据缓存的大小（32KB）
L1i cache:             32K                       # L1 指令缓存的大小（32KB）
L2 cache:              256K                      # L2 缓存的大小（256KB）
L3 cache:              30720K                    # L3 缓存的大小（30MB）
NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22  # NUMA 节点 0 上的 CPU 线程列表
NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23  # NUMA 节点 1 上的 CPU 线程列表
```



## 二、cache缓存区分

### 2.1 缓存种类与各自作用

缓存层次中的 **L** 是 **Level**（层级）的缩写，用来表示缓存的层次； 一般的 CPU 通常有 **三级缓存（L1、L2、L3）**，其中：

- L1 缓存速度最快，容量最小。
- L2 缓存容量较大，速度稍慢。
- L3 缓存容量最大，多个核心共享，速度相对较慢。

**其他 CPU 核心无法直接使用本 CPU 核心的 L1 和 L2 缓存**。L1 和 L2 缓存通常是为每个核心独立设计的，专门用于该核心的高速数据访问。它们的设计目的是减少核心对共享资源（如 L3 缓存或内存）的依赖，从而提高每个核心的处理效率。

具体情况如下：

1. **L1 缓存**：
    - 每个 CPU 核心都有独立的 L1 缓存，分为指令缓存（L1i）和数据缓存（L1d）。
    - L1 缓存仅供所在的核心使用，不与其他核心共享，也无法被其他核心直接访问。
    - 如果其他核心需要访问相同数据，它必须从自己的缓存或更高层缓存（如 L3 缓存或主内存）获取。
2. **L2 缓存**：
    - L2 缓存通常也是为每个核心独立分配的，尽管它比 L1 缓存容量大，仍然属于核心的私有缓存。
    - 像 L1 缓存一样，其他核心无法直接访问某个核心的 L2 缓存。

**共享缓存的情况**

- **L3 缓存**：L3 缓存是多个核心共享的缓存层。多个核心可以访问 L3 缓存中的数据，用于协同处理和减少主内存访问。L3 缓存的共享机制有助于在多核 CPU 上提高数据一致性和性能。

**缓存一致性机制**

虽然其他核心无法直接访问本核心的 L1 和 L2 缓存，但现代多核 CPU 通过 **缓存一致性协议**（如 **MESI**）确保当多个核心访问相同数据时，缓存中的数据保持一致。例如：

- 当一个核心修改了某个数据，缓存一致性协议会将其他核心缓存中该数据的副本标记为无效。
- 当其他核心需要访问被修改的数据时，它必须从共享的 L3 缓存或主内存中重新加载该数据。

**总结**：**L1 和 L2 缓存是核心私有的，不能被其他核心直接使用。多个核心之间只能共享 L3 缓存，同时通过缓存一致性协议保持缓存数据的一致性。**

```less
// 根据lscpu中显示
L1d cache:             32K   数据data
L1i cache:             32K   指令instruct
L2 cache:              256K
L3 cache:              30720K  3M
```



### 2.2 cache一致性问题(L3)

#### 2.2.1 冲突和相关机制

在多核处理器中，**L3 缓存**是多个核心共享的，尽管它能有效减少对主内存的访问并提高性能，但共享缓存也会引发一些潜在的冲突或问题，特别是在高并发访问的情况下。主要的冲突和相关机制如下：

1. **缓存争用 (Cache Contention)**：

- **定义**：缓存争用是指当多个核心频繁访问的数据量超出 L3 缓存的容量时，L3 缓存会按照一定的替换策略（如 LRU，最近最少使用）将旧数据替换掉。如果核心频繁请求的新数据导致原先存储在 L3 中的其他数据被替换，这可能会引起更多的 **cache miss**，进而增加主内存的访问负担。

​		因此，冲突的根本原因在于缓存容量不足，而不是核心访问不同数据本身。如果 L3 缓存足够大以存储所有需要的数据，访问不同数据不会引发替换问题。

- **影响**：这会增加缓存的失效率，导致需要更多时间从较慢的主内存中获取数据，从而影响整体性能。

2. **缓存一致性开销 (Cache Coherency Overhead)**：

- **定义**：为了保持各个核心缓存中的数据一致性，现代多核处理器通常使用 **缓存一致性协议**（如 MESI 协议）。当一个核心修改了某个数据，其他核心的缓存（包括 L3 缓存）需要更新或失效。这会导致一些额外的通信和协调开销，尤其是在并发修改数据时。

- **影响**：缓存一致性操作需要在核心之间进行数据同步，可能会带来延迟。尤其当多个核心频繁访问或修改同一块数据时，会显著增加总线流量，影响性能。

    ```less
    ### 缓存冲突和一致性维护机制
    
    写回（Write-Back）缓存：如果 CPU 修改了某个数据，只会修改缓存中的数据，而不立即写回主存。只有当这个缓存行被替换时，修改后的数据才会写回主存。这种机制需要通过一致性协议来通知其他缓存，告知数据已被修改。
    写通（Write-Through）缓存：当数据被修改时，数据不仅写入缓存，还会直接写回主存。这种策略可以减少一致性维护的复杂性，但通常会带来较大的内存带宽消耗。
    缓存无效化（Invalidate）机制：当某个核心修改了缓存数据后，会通过一致性协议将其他核心或缓存中的该数据标记为无效，确保其他核心读取的始终是最新的数据。
    ```

    

3. **伪共享 (False Sharing)**：

- **定义**：伪共享是指多个核心访问的数据位于同一个缓存行中（通常为 64 字节），但核心并没有访问相同的数据项。由于缓存是一行一行地同步的，当一个核心修改缓存行中的某个字节时，整个缓存行需要同步，导致其他核心的缓存行失效，尽管它们访问的可能是该行中的不同数据。
- **影响**：伪共享会导致频繁的缓存行无效化和重新加载，从而增加内存访问时间，并降低 L3 缓存的实际利用效率。

4. **替换策略 (Cache Eviction Policies)**：

- **定义**：L3 缓存通常使用一些替换策略（如 **LRU**，最近最少使用）来决定在缓存空间不足时哪些数据块应该被移除。由于 L3 是多个核心共享的，某个核心的频繁数据访问可能会导致其他核心的数据被替换出去，增加其访问的 **cache miss** 率。
- **影响**：不同核心的任务可能对缓存的需求不同，一个核心的高频数据访问可能会影响其他核心的缓存命中率，从而造成性能瓶颈。

5. **内存分配的局部性 (Memory Locality)**：

- **定义**：在 NUMA（非一致性内存访问）架构中，不同的 CPU 核心（或 CPU 套接字）具有自己独立的内存控制器和本地内存区域。如果不同核心访问的是不属于自己本地内存的区域，可能会导致额外的内存访问延迟，尽管数据在 L3 缓存中共享。
- **影响**：跨 NUMA 节点的访问需要通过较慢的总线，可能会引入显著的延迟，即使缓存命中，也不能完全消除这个问题。



#### 2.2.2 缓解方法

1. **NUMA 感知调度**：在 NUMA 系统中，操作系统可以根据 CPU 和内存的拓扑结构，尽可能将任务调度到与其数据较近的核心上，减少跨节点访问。
2. **优化数据局部性**：程序设计时可以尽量将频繁访问的数据放在一起，减少不同核心访问共享缓存行的可能性，避免伪共享问题。
3. **硬件优化**：处理器在设计 L3 缓存时，可能采用更智能的替换策略和预取机制，减少核心之间的缓存争用和一致性协调开销。





## 三、预取

“预取”（prefetch）是一个重要的优化技术。预取指令的目的是为了提高数据访问的效率，减少延迟。以下是有关预取指令的详细说明，包括其功能逻辑、效果以及对 CPU 和内存的影响：

### 3.1 原理逻辑

**1. 预取指令的基本原理**

- **目的**：预取指令的主要目的是提前将数据从内存加载到缓存中，以便当实际访问这些数据时，可以减少访问延迟。预取指令告诉 CPU 预测某个数据块很快会被使用，因此提前将其加载到缓存中。
- **实现**：在程序中插入预取指令，指示 CPU 预先加载即将使用的数据。CPU 会在数据实际被访问之前将其加载到高速缓存（如 L1、L2、L3）中。

**2. 预取指令的效果**

- **减少缓存未命中**：通过提前加载数据到缓存中，减少数据访问时的缓存未命中率，提高数据访问效率。
- **提高流水线效率**：预取指令可以减少由于数据访问造成的流水线停顿，提高 CPU 流水线的效率。
- **减少等待时间**：在数据访问之前，预取可以减少 CPU 等待内存访问的时间，从而提高整体性能。



### 3.2 对cpu/内存的影响

**1. 对 CPU 的影响**

- **减少等待时间**：通过将数据提前加载到缓存中，预取操作减少了 CPU 等待内存访问的时间，使 CPU 能够更快地处理数据。
- **提高吞吐量**：提高缓存的命中率，使 CPU 能够更高效地处理大量数据，提高程序的总体吞吐量。

**2. 对内存的影响**

- **减少内存访问延迟**：预取操作减少了数据从内存到 CPU 的延迟，因为数据已经被加载到缓存中，访问速度更快。
- **增加内存带宽需求**：虽然预取可以提高性能，但也可能增加内存带宽的需求，因为它提前加载的数据可能占用额外的带宽。

**示例**

考虑一个简单的例子，我们有一个大数组需要遍历：

```c
#include <stdio.h>

#define SIZE 1024
#define PREFETCH_DISTANCE 16

void process_array(int *arr, int size) {
    for (int i = 0; i < size; i += PREFETCH_DISTANCE) {
        // 预取处理
        __builtin_prefetch(&arr[i + PREFETCH_DISTANCE], 0, 1);
        // 处理当前数据
        for (int j = 0; j < PREFETCH_DISTANCE; ++j) {
            arr[i + j] += 1;
        }
    }
}
```

在这个例子中，`__builtin_prefetch` 是一个内建函数，它告诉编译器在处理当前数据时，提前加载数组中的后续数据。

### 3.3 为什么会产生这样的效果

- **内存访问延迟**：内存访问比 CPU 缓存访问要慢得多。预取操作通过将数据提前加载到缓存中，减少了这种延迟。
- **数据局部性**：数据通常在处理时具有局部性，即程序在短时间内会频繁访问相邻的数据。预取利用这种局部性，提前加载可能会被访问的数据，提高缓存命中率。



### 3.4 预取的数据是存储在那一级缓存中

预取的数据通常存储在 CPU 的**L1**、**L2** 或 **L3** 级缓存中，具体存储在哪一级缓存取决于以下几个因素：

#### 1. **预取的数据存储位置**

**L1 缓存**：

- **描述**：L1 缓存是最接近处理核心的缓存，通常分为 L1 数据缓存（L1D）和 L1 指令缓存（L1I）。预取的数据首先会被加载到 L1 数据缓存中。
- **特点**：L1 缓存容量较小（通常在 16KB 到 64KB 之间），但访问速度最快。如果预取的数据频繁被访问，它会在 L1 缓存中找到。

**L2 缓存**：

- **描述**：L2 缓存位于 L1 缓存和 L3 缓存之间，通常用于存储较大容量的数据。预取的数据如果在 L1 缓存中被替换或者需要更大的容量，它们会被存储在 L2 缓存中。
- **特点**：L2 缓存容量较大（通常在 256KB 到 1MB 之间），访问速度次于 L1，但通常比 L3 快。

**L3 缓存**：

- **描述**：L3 缓存是共享缓存，通常在多个核心之间共享。预取的数据如果不适合存储在 L1 或 L2 缓存中，它们会被存储在 L3 缓存中。
- **特点**：L3 缓存容量更大（通常在 2MB 到 32MB 之间），访问速度最慢，但可以服务于多个核心。

#### 2. **预取策略的影响**

**预取算法**：

- **预取算法**决定了数据预取的策略和存储位置。通常，预取指令会使 CPU 预先加载数据到 L1 缓存，但如果 L1 缓存没有足够的空间，数据会逐级转移到 L2 或 L3 缓存中。
- **动态调整**：现代处理器可能会动态调整预取策略，根据实际的数据访问模式选择合适的缓存级别进行预取。

**数据使用频率**：

- **频繁使用的数据**：如果预取的数据频繁被使用，它们会留在较低级别的缓存（如 L1 或 L2），因为这样可以更快地访问这些数据。
- **不常用的数据**：如果预取的数据没有被频繁访问，它们可能会被逐步移到较高级别的缓存（如 L3），或者在缓存被清空时被丢弃。

#### 3. **缓存替换策略**

**缓存替换策略**：

- **替换算法**：当缓存空间不足时，缓存替换策略（如 LRU（Least Recently Used））会决定哪些数据被替换。预取的数据可能会被替换，尤其是当缓存空间有限时。
- **缓存一致性**：处理器还会确保不同级别缓存之间的数据一致性。即使预取的数据在不同缓存级别之间迁移，它们仍然会保持一致。

**总结**

```apl
	预取的数据会根据其被预取后的使用情况和缓存的容量逐级存储在 L1、L2 或 L3 缓存中。预取的主要目标是通过提前将数据加载到缓存中，减少实际数据访问的延迟，从而提高程序性能。缓存的层级结构和预取策略共同决定了数据存储的位置和处理方式。
```



### 3.5  __builtin_prefetch预取函数(可以确定cache的缓存级别)

具体说明可以查看：https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html

#### 1、函数说明

dpdk中常见的使用示例：

```c
__builtin_prefetch(p, 0, 0);
__builtin_prefetch(p, 1, 0);
__builtin_prefetch(p, 1, 3)
```

是 GCC 编译器内建的预取函数，用于优化程序的缓存性能。它将 `p` 地址指向的数据预取到缓存中，以减少数据访问延迟。下面是对这个函数调用的详细描述：

`__builtin_prefetch` 函数的参数

```c
void __builtin_prefetch(const void *addr, int rw, int locality);
```

- **`addr`**: 数据的内存地址。这里是 `p`。如果 addr 无效，则数据预取不会生成错误，但地址表达式本身必须有效。例如，如果 `p->next` 不是有效地址，则 `p->next` 的预取不会出错，但如果 `p` 不是有效地址，则评估会出错。
- **`rw`**: 预取的类型。
    - **`0`：数据将被读取。**
    - **`1`：数据将被读取和写入。**
- **`locality`**: 数据的局部性。用于指示数据的访问模式。
    - `0`：低局部性。
    - `1`：高局部性。
    - `2`：更高的局部性。
    - **`3`：最高的局部性。**

值 3 表示数据具有高度的时态局部性，应尽可能保留在所有级别的缓存中。值 1 和 2 分别表示低或中等程度的时间局部性。**默认值为 3**。

**预取行为**

- **预取到缓存**: `__builtin_prefetch(p, 1, 3);` 会尝试将 `p` 指向的数据提前加载到缓存中。由于 `rw=1`，编译器会优化以支持数据的读取和写入操作。
- **局部性处理**: `locality=3` 提供了数据访问的强预测，预取操作会尽量将数据保留在缓存中，以便在未来需要时能够更快地访问。

**使用场景**

- **高性能计算**: 在需要频繁访问和修改数据的大规模计算中，预取数据到缓存可以显著减少缓存未命中导致的延迟。
- **内存访问模式**: 当程序的访问模式显示数据将被频繁读取和写入时，可以使用这样的预取指令来优化性能。



#### 2、`locality` 参数与缓存级别的关系

1. **`locality=0` (低局部性)**：
    - **描述**：数据的局部性较低，访问频率不高。
    - **影响**：编译器将数据加载到缓存中，但可能不会对其保留时间进行优化。数据可能会在 L3 缓存中，而不是 L1 或 L2 中，特别是在缓存空间紧张时。
2. **`locality=1` (中等局部性)**：
    - **描述**：数据访问频率中等，具有一定规律性。
    - **影响**：编译器将数据加载到缓存中，并优化其在 L2 缓存中的保留时间。数据有可能在 L1、L2 或 L3 缓存中，取决于实际的缓存需求和空间。
3. **`locality=2` (较高局部性)**：
    - **描述**：数据访问频繁，访问模式较为规律。
    - **影响**：编译器会将数据优先加载到 L2 或 L1 缓存中，并尽可能长时间保留。数据会更有可能在 L1 或 L2 缓存中，特别是在需要频繁访问时。
4. **`locality=3` (最高局部性)**：
    - **描述**：数据访问非常频繁，访问模式非常规律。
    - **影响**：编译器会尽可能将数据保留在 L1 或 L2 缓存中，以减少延迟。数据在 L1 或 L2 缓存中的概率非常高。

**实际缓存映射**

- **CPU 架构决定映射**：具体的数据会被加载到哪个缓存级别（L1、L2、L3）由 CPU 架构决定。`locality` 参数影响编译器的预取策略，但并不直接控制数据的具体缓存级别。
- **缓存替换策略**：缓存的替换策略（例如，LRU、FIFO）和缓存容量决定了数据在缓存中的保留情况。即使 `locality` 设置为最高，也可能由于缓存空间限制，数据最终会存储在 L2 或 L3 缓存中。
- **预取行为**：编译器根据 `locality` 提示优化预取策略。虽然 `locality` 参数影响数据的预取和保留，但缓存层次（L1、L2、L3）的具体映射还是由 CPU 的硬件设计和缓存管理策略决定。

**示例**：假设一个处理器的 L1 和 L2 缓存非常小，L3 缓存比较大：

- **`locality=3`**：编译器会尝试将数据加载到 L1 和 L2 缓存中，以便高效地处理数据访问。但如果 L1 和 L2 缓存空间不足，数据可能会被缓存在 L3 中。
- **`locality=0`**：数据可能会被预取到 L3 缓存中，因为该数据的访问频率较低，L3 缓存提供了更大的空间来存储这些数据。